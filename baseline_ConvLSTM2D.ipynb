{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "baseline-ConvLSTM2D.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GqC6eu9lxKsA"
      },
      "source": [
        "# 导入包"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQq9lVRDxKsE"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import lightgbm as lgb\n",
        "from scipy.stats import skew\n",
        "from scipy.stats import kurtosis\n",
        "from scipy.stats import mode\n",
        "\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from collections import Counter\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n",
        "import warnings \n",
        "warnings.filterwarnings(\"ignore\")                                               "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ONZ4umdxKsU"
      },
      "source": [
        "# 导入数据"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-Kl3IRlxKsZ"
      },
      "source": [
        "nrows = None\n",
        "\n",
        "df_train = pd.read_csv('/content/drive/My Drive/Colab Notebooks/sensor_class/sensor_train.csv',sep=',',nrows=nrows)\n",
        "df_test = pd.read_csv('/content/drive/My Drive/Colab Notebooks/sensor_class/sensor_test.csv',sep=',',nrows=nrows)\n",
        "df_submit = pd.read_csv('/content/drive/My Drive/Colab Notebooks/sensor_class/提交结果示例.csv',sep=',',nrows=nrows)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fVOnke8o71Pb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a7f6effb-9475-4cdc-f8e7-fdd5a60b7991"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Y3PidmtxKsw"
      },
      "source": [
        "# 合并数据"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r5wg4cjuxKtC"
      },
      "source": [
        "df_train['acc_all'] = (df_train['acc_x'] ** 2 + df_train['acc_y'] ** 2 + df_train['acc_z'] ** 2) ** 0.5\n",
        "df_train['acc_allg'] = (df_train['acc_xg'] ** 2 + df_train['acc_yg'] ** 2 + df_train['acc_zg'] ** 2) ** 0.5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QgcnlzTZ2jI5"
      },
      "source": [
        "df_test['acc_all'] = (df_test['acc_x'] ** 2 + df_test['acc_y'] ** 2 + df_test['acc_z'] ** 2) ** 0.5\n",
        "df_test['acc_allg'] = (df_test['acc_xg'] ** 2 + df_test['acc_yg'] ** 2 + df_test['acc_zg'] ** 2) ** 0.5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oioxg8JLxKtZ"
      },
      "source": [
        "# 数据聚合"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KAtv3wMsbL4d"
      },
      "source": [
        "y=df_train.groupby('fragment_id')['behavior_id'].min()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "so4PcqvazOdy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "cd4cd23d-c37d-43f5-ebab-ed1c16c8937d"
      },
      "source": [
        "from scipy.signal import resample\n",
        "size_df_train=df_train.groupby('fragment_id').size().count()\n",
        "size_df_test=df_test.groupby('fragment_id').size().count()\n",
        "x = np.zeros((size_df_train, 60, 8, 1))\n",
        "t = np.zeros((size_df_test, 60, 8, 1))\n",
        "\n",
        "for i in tqdm(range(size_df_train)):\n",
        "    tmp = df_train[df_train.fragment_id == i][:60]\n",
        "    a=resample(tmp.drop(['fragment_id', 'time_point', 'behavior_id'],axis=1), 60, np.array(tmp.time_point))\n",
        "    x[i,:,:, 0] = a[0]\n",
        "\n",
        "for i in tqdm(range(size_df_test)):\n",
        "\n",
        "    tmp = df_test[df_test.fragment_id == i][:60]\n",
        "    a=resample(tmp.drop(['fragment_id', 'time_point'],axis=1), 60, np.array(tmp.time_point))\n",
        "    t[i,:,:, 0] = a[0]\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 7292/7292 [00:15<00:00, 482.59it/s]\n",
            "100%|██████████| 7500/7500 [00:15<00:00, 486.96it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OXnHaa08xKto"
      },
      "source": [
        "# 查看聚合后的数据"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qiqSnlUHxKty"
      },
      "source": [
        "# 特征处理"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_0EascOxKuF"
      },
      "source": [
        "# 模型训练 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FFnVLzwVxKuL"
      },
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM \n",
        "from keras.layers.core import Dense, Dropout\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "from numpy import dstack\n",
        "from pandas import read_csv\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import TimeDistributed\n",
        "from keras.layers.convolutional import Conv1D\n",
        "from keras.layers.convolutional import MaxPooling1D\n",
        "from keras.layers import ConvLSTM2D,Bidirectional\n",
        "from keras.utils import to_categorical\n",
        "from matplotlib import pyplot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t32e9rs6xKuS"
      },
      "source": [
        "X = x\n",
        "X_test = t"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "svWan6Ge-oOy"
      },
      "source": [
        "y=df_train.groupby('fragment_id')['behavior_id'].min()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rm5KVdkwCum5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1ad51c38-b302-4ae1-f553-a282afec26ea"
      },
      "source": [
        "X.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7292, 60, 8, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6TVaLTVXxKvZ"
      },
      "source": [
        "# LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5bFCEjxXxKvb"
      },
      "source": [
        "df_train_stacking = pd.DataFrame(np.zeros((X.shape[0],19)))\n",
        "df_test_stacking = pd.DataFrame(np.zeros((X_test.shape[0],19)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LepByhKaxKvh"
      },
      "source": [
        "seed = 2020\n",
        "folds = 2\n",
        "kfold = StratifiedKFold(n_splits=folds, shuffle=True, random_state=seed)\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from keras.callbacks import ModelCheckpoint\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MdV8sIqZxKvm"
      },
      "source": [
        "# 训练模型"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m52Y2LBYuDHz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6eba2a0b-57ea-4f2b-e986-dcb2e47e08f6"
      },
      "source": [
        "for fold,(train_index, val_index) in enumerate(kfold.split(X, y)):\n",
        "\n",
        "\n",
        "  print('--------------- begin ---------------')\n",
        "  X_train, X_val = np.array(list(X[train_index])), np.array(list(X[val_index]))\n",
        "  y_train, y_val = np.array(list(y[train_index])), np.array(list(y[val_index]))\n",
        "  \t# one hot encode y\n",
        "  y_train = to_categorical(y_train)\n",
        "  y_val = to_categorical(y_val)\n",
        "     \n",
        "\t# define model\n",
        "  verbose, epochs, batch_size = 1, 25, 32\n",
        "  n_timesteps, n_features, n_outputs = X_train.shape[1], X_train.shape[2], y_train.shape[1]\n",
        "  # reshape into subsequences (samples, time steps, rows, cols, channels)\n",
        "  n_steps, n_length = 2, 30\n",
        "  X_train = X_train.reshape((X_train.shape[0], n_steps, 1, n_length, n_features))\n",
        "  X_val = X_val.reshape((X_val.shape[0], n_steps, 1, n_length, n_features))\n",
        "\n",
        "  X_test = np.array(list(X_test))\n",
        "  X_test = X_test.reshape((X_test.shape[0], n_steps, 1, n_length, n_features))\n",
        "  # define model\n",
        "  model = Sequential()\n",
        "  model.add(Bidirectional(ConvLSTM2D(filters=128, kernel_size=(1,4), activation='relu', input_shape=(n_steps, 1, n_length, n_features))))\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(100, activation='relu'))\n",
        "  model.add(Dense(n_outputs, activation='softmax'))\n",
        "  # fit network\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "  plateau = ReduceLROnPlateau(monitor=\"val_accuracy\",\n",
        "                              verbose=0,\n",
        "                              mode='max',\n",
        "                              factor=0.1,\n",
        "                              patience=6)\n",
        "  early_stopping = EarlyStopping(monitor='val_accuracy',\n",
        "                                  verbose=0,\n",
        "                                  mode='max',\n",
        "                                  patience=10)\n",
        "  checkpoint = ModelCheckpoint(f'./fold{fold}.h5',\n",
        "                                monitor='val_accuracy',\n",
        "                                verbose=0,\n",
        "                                mode='max',\n",
        "                                save_weights_only=True,\n",
        "                                save_best_only=True)\n",
        "  # model.summary()\n",
        "\n",
        "  if os.path.exists(f'./fold{fold}.h5'):\n",
        "      print('-------------load the model-----------------')\n",
        "      model.load_weights(f'./fold{fold}.h5')\n",
        "\n",
        "\n",
        "  history=model.fit(X_train, y_train, \n",
        "            epochs=epochs, \n",
        "            batch_size=batch_size, \n",
        "            verbose=verbose,\n",
        "            validation_data=(X_val, y_val),\n",
        "            callbacks=[plateau, early_stopping, checkpoint])\n",
        "  # evaluate modelg \n",
        "  model.summary()\n",
        "  X_val_predict = model.predict(X_val)\n",
        "  X_test_predict = model.predict(X_test)\n",
        "    \n",
        "  df_train_stacking.loc[val_index,:] = X_val_predict\n",
        "  df_test_stacking[:] += X_test_predict / folds\n",
        "  print('--------------- end ---------------')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--------------- begin ---------------\n",
            "Train on 5833 samples, validate on 1459 samples\n",
            "Epoch 1/5\n",
            "5833/5833 [==============================] - 33s 6ms/step - loss: 2.0890 - accuracy: 0.3120 - val_loss: 1.8521 - val_accuracy: 0.3592\n",
            "Epoch 2/5\n",
            "5833/5833 [==============================] - 31s 5ms/step - loss: 1.7272 - accuracy: 0.4027 - val_loss: 1.7460 - val_accuracy: 0.4099\n",
            "Epoch 3/5\n",
            "5833/5833 [==============================] - 31s 5ms/step - loss: 1.6089 - accuracy: 0.4389 - val_loss: 1.5807 - val_accuracy: 0.4332\n",
            "Epoch 4/5\n",
            "5833/5833 [==============================] - 31s 5ms/step - loss: 1.5150 - accuracy: 0.4545 - val_loss: 1.5405 - val_accuracy: 0.4668\n",
            "Epoch 5/5\n",
            "5833/5833 [==============================] - 31s 5ms/step - loss: 1.4276 - accuracy: 0.4871 - val_loss: 1.5134 - val_accuracy: 0.4620\n",
            "Model: \"sequential_25\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "bidirectional_3 (Bidirection (None, 1, 27, 256)        558080    \n",
            "_________________________________________________________________\n",
            "dropout_19 (Dropout)         (None, 1, 27, 256)        0         \n",
            "_________________________________________________________________\n",
            "flatten_19 (Flatten)         (None, 6912)              0         \n",
            "_________________________________________________________________\n",
            "dense_37 (Dense)             (None, 100)               691300    \n",
            "_________________________________________________________________\n",
            "dense_38 (Dense)             (None, 19)                1919      \n",
            "=================================================================\n",
            "Total params: 1,251,299\n",
            "Trainable params: 1,251,299\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "--------------- end ---------------\n",
            "--------------- begin ---------------\n",
            "Train on 5833 samples, validate on 1459 samples\n",
            "Epoch 1/5\n",
            "5833/5833 [==============================] - 33s 6ms/step - loss: 2.1161 - accuracy: 0.3081 - val_loss: 1.8650 - val_accuracy: 0.3612\n",
            "Epoch 2/5\n",
            "4448/5833 [=====================>........] - ETA: 6s - loss: 1.7242 - accuracy: 0.3955"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-95-ed3d18a70a1c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m             callbacks=[plateau, early_stopping, checkpoint])\n\u001b[0m\u001b[1;32m     59\u001b[0m   \u001b[0;31m# evaluate modelg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3790\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3791\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3792\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3793\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3794\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1603\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1604\u001b[0m     \"\"\"\n\u001b[0;32m-> 1605\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1607\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1643\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1644\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1645\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1647\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pw855QVGxKvs"
      },
      "source": [
        "# 验证和输出结果"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wsqmFo5lxsAu"
      },
      "source": [
        "def accuracy(y_true, y_pred):\n",
        "    return tf.keras.metrics.sparse_top_k_categorical_accuracy(y_true, y_pred, k=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VgiK07JgEJeC"
      },
      "source": [
        "def acc_combo(y, y_pred):\n",
        "    # 数值ID与行为编码的对应关系\n",
        "    mapping = {0: 'A_0', 1: 'A_1', 2: 'A_2', 3: 'A_3', \n",
        "        4: 'D_4', 5: 'A_5', 6: 'B_1',7: 'B_5', \n",
        "        8: 'B_2', 9: 'B_3', 10: 'B_0', 11: 'A_6', \n",
        "        12: 'C_1', 13: 'C_3', 14: 'C_0', 15: 'B_6', \n",
        "        16: 'C_2', 17: 'C_5', 18: 'C_6'}\n",
        "    # 将行为ID转为编码\n",
        "    code_y, code_y_pred = mapping[y], mapping[y_pred]\n",
        "    if code_y == code_y_pred: #编码完全相同得分1.0\n",
        "        return 1.0\n",
        "    elif code_y.split(\"_\")[0] == code_y_pred.split(\"_\")[0]: #编码仅字母部分相同得分1.0/7\n",
        "        return 1.0/7\n",
        "    elif code_y.split(\"_\")[1] == code_y_pred.split(\"_\")[1]: #编码仅数字部分相同得分1.0/3\n",
        "        return 1.0/3\n",
        "    else:\n",
        "        return 0.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZQRlIqOxKvt"
      },
      "source": [
        "labels = np.argmax(df_test_stacking.values, axis=1)\n",
        "pred_y = np.argmax(df_train_stacking.values, axis=1)\n",
        "\n",
        "\n",
        "acc_scores = round(accuracy_score(y, pred_y), 5)\n",
        "acc_combo_scores = round(sum(acc_combo(y_true, y_pred) for y_true, y_pred in zip(y, pred_y)) / len(list(y)),5)\n",
        "\n",
        "print('--------')\n",
        "print(' acc : ', acc_scores, 'acc_combo : ', acc_combo_scores)\n",
        "\n",
        "df_out =df_test.groupby('fragment_id')['fragment_id'].min()\n",
        "df_out['behavior_id'] = labels\n",
        "df_out.to_csv('./submit_lstm_%.5f_%.5f.csv' % (acc_scores, acc_combo_scores), index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZNgeb3aGXIx"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def plot_graphs(history, string):\n",
        "  plt.plot(history.history[string])\n",
        "  plt.plot(history.history['val_'+string])\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(string)\n",
        "  plt.legend([string, 'val_'+string])\n",
        "  plt.show()\n",
        "  \n",
        "plot_graphs(history, \"accuracy\")\n",
        "plot_graphs(history, \"loss\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}