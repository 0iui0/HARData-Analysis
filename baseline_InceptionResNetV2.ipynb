{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "baseline-InceptionResNetV2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GqC6eu9lxKsA"
      },
      "source": [
        "# 导入包"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQq9lVRDxKsE"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import lightgbm as lgb\n",
        "from scipy.stats import skew\n",
        "from scipy.stats import kurtosis\n",
        "from scipy.stats import mode\n",
        "\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from collections import Counter\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n",
        "import warnings \n",
        "warnings.filterwarnings(\"ignore\")                                               "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ONZ4umdxKsU"
      },
      "source": [
        "# 导入数据"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-Kl3IRlxKsZ"
      },
      "source": [
        "nrows = None\n",
        "\n",
        "df_train = pd.read_csv('/content/drive/My Drive/Colab Notebooks/sensor_class/sensor_train.csv',sep=',',nrows=nrows)\n",
        "df_test = pd.read_csv('/content/drive/My Drive/Colab Notebooks/sensor_class/sensor_test.csv',sep=',',nrows=nrows)\n",
        "df_submit = pd.read_csv('/content/drive/My Drive/Colab Notebooks/sensor_class/提交结果示例.csv',sep=',',nrows=nrows)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9PJDd0tTEOv"
      },
      "source": [
        "df_train.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRODKgfeEblw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "outputId": "a161e17b-e16c-4ff1-a62d-01509d4701ef"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Y3PidmtxKsw"
      },
      "source": [
        "# 合并数据"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r5wg4cjuxKtC"
      },
      "source": [
        "df_train['acc_all'] = (df_train['acc_x'] ** 2 + df_train['acc_y'] ** 2 + df_train['acc_z'] ** 2) ** 0.5\n",
        "df_train['acc_allg'] = (df_train['acc_xg'] ** 2 + df_train['acc_yg'] ** 2 + df_train['acc_zg'] ** 2) ** 0.5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QgcnlzTZ2jI5"
      },
      "source": [
        "df_test['acc_all'] = (df_test['acc_x'] ** 2 + df_test['acc_y'] ** 2 + df_test['acc_z'] ** 2) ** 0.5\n",
        "df_test['acc_allg'] = (df_test['acc_xg'] ** 2 + df_test['acc_yg'] ** 2 + df_test['acc_zg'] ** 2) ** 0.5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kpl-RzMH3oOD"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A7T6ySPASjHr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "ea5dc25b-3988-4e97-8f64-7f0657b04b0a"
      },
      "source": [
        "df_train['time_point'].diff(periods=1).dropna()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1         81.0\n",
              "2         90.0\n",
              "3         99.0\n",
              "4         91.0\n",
              "5         83.0\n",
              "          ... \n",
              "425354    84.0\n",
              "425355    86.0\n",
              "425356    88.0\n",
              "425357    95.0\n",
              "425358    87.0\n",
              "Name: time_point, Length: 425358, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oioxg8JLxKtZ"
      },
      "source": [
        "# 数据聚合"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KAtv3wMsbL4d"
      },
      "source": [
        "y=df_train.groupby('fragment_id')['behavior_id'].min()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "so4PcqvazOdy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "bfe39669-1157-4663-d68c-2ad4193c53ef"
      },
      "source": [
        "from scipy.signal import resample\n",
        "size_df_train=df_train.groupby('fragment_id').size().count()\n",
        "size_df_test=df_test.groupby('fragment_id').size().count()\n",
        "x = np.zeros((size_df_train, 60, 8, 1))\n",
        "t = np.zeros((size_df_test, 60, 8, 1))\n",
        "\n",
        "for i in tqdm(range(size_df_train)):\n",
        "    tmp = df_train[df_train.fragment_id == i][:60]\n",
        "    a=resample(tmp.drop(['fragment_id', 'time_point', 'behavior_id'],axis=1), 75, np.array(tmp.time_point))\n",
        "    x[i,:,:, 0] = a[0]\n",
        "\n",
        "for i in tqdm(range(size_df_test)):\n",
        "\n",
        "    tmp = df_test[df_test.fragment_id == i][:60]\n",
        "    a=resample(tmp.drop(['fragment_id', 'time_point'],axis=1), 75, np.array(tmp.time_point))\n",
        "    t[i,:,:, 0] = a[0]\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 7292/7292 [00:15<00:00, 480.00it/s]\n",
            "100%|██████████| 7500/7500 [00:15<00:00, 480.16it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_0EascOxKuF"
      },
      "source": [
        "# 模型训练 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FFnVLzwVxKuL"
      },
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM \n",
        "from keras.layers.core import Dense, Dropout\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "from numpy import dstack\n",
        "from pandas import read_csv\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import TimeDistributed\n",
        "from keras.layers.convolutional import Conv1D\n",
        "from keras.layers.convolutional import MaxPooling1D\n",
        "from keras.layers import ConvLSTM2D,Bidirectional\n",
        "from keras.utils import to_categorical\n",
        "from matplotlib import pyplot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t32e9rs6xKuS"
      },
      "source": [
        "X = x\n",
        "X_test = t"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "svWan6Ge-oOy"
      },
      "source": [
        "y=df_train.groupby('fragment_id')['behavior_id'].min()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rm5KVdkwCum5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "70fea229-79e8-4dde-c529-95c75cc62fe3"
      },
      "source": [
        "X.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7292, 60, 8, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6TVaLTVXxKvZ"
      },
      "source": [
        "# LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5bFCEjxXxKvb"
      },
      "source": [
        "df_train_stacking = pd.DataFrame(np.zeros((X.shape[0],19)))\n",
        "df_test_stacking = pd.DataFrame(np.zeros((X_test.shape[0],19)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LepByhKaxKvh"
      },
      "source": [
        "seed = 2020\n",
        "folds = 2\n",
        "kfold = StratifiedKFold(n_splits=folds, shuffle=True, random_state=seed)\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from keras.callbacks import ModelCheckpoint\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kEnUjf1BDi2m"
      },
      "source": [
        "\n",
        "# Import the inception model  \n",
        "from keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
        "pre_trained_model = InceptionResNetV2(include_top=False, weights='imagenet',  input_shape=(60, 10, 3), pooling='avg', classes=19)\n",
        "\n",
        "# Make all the layers in the pre-trained model non-trainable\n",
        "for layer in pre_trained_model.layers:\n",
        "  layer.trainable = False\n",
        "  \n",
        "# Print the model summary\n",
        "pre_trained_model.summary()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSSJ8507oBfw"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UrG9gwVeFHlN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7a9bab74-bf5b-46b9-82c4-57af42e5d9b1"
      },
      "source": [
        "last_layer = pre_trained_model.get_layer('mixed7')\n",
        "print('last layer output shape: ', last_layer.output_shape)\n",
        "last_output = last_layer.output"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "last layer output shape:  (None, 7, 7, 768)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYmtJjgRFp6q"
      },
      "source": [
        "\n",
        "from tensorflow.keras.optimizers import RMSprop\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MdV8sIqZxKvm"
      },
      "source": [
        "# 训练模型"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m52Y2LBYuDHz"
      },
      "source": [
        "for fold,(train_index, val_index) in enumerate(kfold.split(X, y)):\n",
        "\n",
        "\n",
        "  print('--------------- begin ---------------')\n",
        "  X_train, X_val = np.array(list(X[train_index])), np.array(list(X[val_index]))\n",
        "  y_train, y_val = np.array(list(y[train_index])), np.array(list(y[val_index]))\n",
        "  \t# one hot encode y\n",
        "  y_train = to_categorical(y_train)\n",
        "  y_val = to_categorical(y_val)\n",
        "     \n",
        "\t# define model\n",
        "  verbose, epochs, batch_size = 1, 25, 32\n",
        "  n_timesteps, n_features, n_outputs = X_train.shape[1], X_train.shape[2], y_train.shape[1]\n",
        "  # reshape into subsequences (samples, time steps, rows, cols, channels)\n",
        "  n_steps, n_length = 2, 30\n",
        "  # X_train = X_train.reshape((X_train.shape[0], n_steps, 1, n_length, n_features))\n",
        "  # X_val = X_val.reshape((X_val.shape[0], n_steps, 1, n_length, n_features))\n",
        "\n",
        "  X_test = np.array(list(X_test))\n",
        "  # X_test = X_test.reshape((X_test.shape[0], n_steps, 1, n_length, n_features))\n",
        "  # define model\n",
        "\n",
        "  # Flatten the output layer to 1 dimension\n",
        "  x = layers.Flatten()(last_output)\n",
        "  # Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
        "  x = layers.Dense(1024, activation='relu')(x)\n",
        "  # Add a dropout rate of 0.2\n",
        "  x = layers.Dropout(0.2)(x)                  \n",
        "  # Add a final sigmoid layer for classification\n",
        "  x = layers.Dense(n_outputs, activation='softmax')(x)           \n",
        "\n",
        "  model = Model( pre_trained_model.input, x) \n",
        "\n",
        "  # fit network\n",
        "  model.compile(loss='categorical_crossentropy', RMSprop(lr=0.0001), metrics=['accuracy'])\n",
        "\n",
        "  plateau = ReduceLROnPlateau(monitor=\"val_accuracy\",\n",
        "                              verbose=0,\n",
        "                              mode='max',\n",
        "                              factor=0.1,\n",
        "                              patience=6)\n",
        "  early_stopping = EarlyStopping(monitor='val_accuracy',\n",
        "                                  verbose=0,\n",
        "                                  mode='max',\n",
        "                                  patience=10)\n",
        "  checkpoint = ModelCheckpoint(f'./fold{fold}.h5',\n",
        "                                monitor='val_accuracy',\n",
        "                                verbose=0,\n",
        "                                mode='max',\n",
        "                                save_weights_only=True,\n",
        "                                save_best_only=True)\n",
        "  # model.summary()\n",
        "\n",
        "  if os.path.exists(f'./fold{fold}.h5'):\n",
        "      print('-------------load the model-----------------')\n",
        "      model.load_weights(f'./fold{fold}.h5')\n",
        "\n",
        "\n",
        "  history=model.fit(X_train, y_train, \n",
        "            epochs=epochs, \n",
        "            batch_size=batch_size, \n",
        "            verbose=verbose,\n",
        "            validation_data=(X_val, y_val),\n",
        "            callbacks=[plateau, early_stopping, checkpoint])\n",
        "  # evaluate modelg \n",
        "  model.summary()\n",
        "  X_val_predict = model.predict(X_val)\n",
        "  X_test_predict = model.predict(X_test)\n",
        "    \n",
        "  df_train_stacking.loc[val_index,:] = X_val_predict\n",
        "  df_test_stacking[:] += X_test_predict / folds\n",
        "  print('--------------- end ---------------')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pw855QVGxKvs"
      },
      "source": [
        "# 验证和输出结果"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wsqmFo5lxsAu"
      },
      "source": [
        "def accuracy(y_true, y_pred):\n",
        "    return tf.keras.metrics.sparse_top_k_categorical_accuracy(y_true, y_pred, k=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VgiK07JgEJeC"
      },
      "source": [
        "def acc_combo(y, y_pred):\n",
        "    # 数值ID与行为编码的对应关系\n",
        "    mapping = {0: 'A_0', 1: 'A_1', 2: 'A_2', 3: 'A_3', \n",
        "        4: 'D_4', 5: 'A_5', 6: 'B_1',7: 'B_5', \n",
        "        8: 'B_2', 9: 'B_3', 10: 'B_0', 11: 'A_6', \n",
        "        12: 'C_1', 13: 'C_3', 14: 'C_0', 15: 'B_6', \n",
        "        16: 'C_2', 17: 'C_5', 18: 'C_6'}\n",
        "    # 将行为ID转为编码\n",
        "    code_y, code_y_pred = mapping[y], mapping[y_pred]i\n",
        "    if code_y == code_y_pred: #编码完全相同得分1.0\n",
        "        return 1.0\n",
        "    elif code_y.split(\"_\")[0] == code_y_pred.split(\"_\")[0]: #编码仅字母部分相同得分1.0/7\n",
        "        return 1.0/7\n",
        "    elif code_y.split(\"_\")[1] == code_y_pred.split(\"_\")[1]: #编码仅数字部分相同得分1.0/3\n",
        "        return 1.0/3\n",
        "    else:\n",
        "        return 0.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZQRlIqOxKvt"
      },
      "source": [
        "labels = np.argmax(df_test_stacking.values, axis=1)\n",
        "pred_y = np.argmax(df_train_stacking.values, axis=1)\n",
        "\n",
        "\n",
        "acc_scores = round(accuracy_score(y, pred_y), 5)\n",
        "acc_combo_scores = round(sum(acc_combo(y_true, y_pred) for y_true, y_pred in zip(y, pred_y)) / len(list(y)),5)\n",
        "\n",
        "print('--------')\n",
        "print(' acc : ', acc_scores, 'acc_combo : ', acc_combo_scores)\n",
        "\n",
        "df_out =df_test.groupby('fragment_id')['fragment_id'].min()\n",
        "df_out['behavior_id'] = labels\n",
        "df_out.to_csv('./submit_lstm_%.5f_%.5f.csv' % (acc_scores, acc_combo_scores), index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZNgeb3aGXIx"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_graphs(history, string):\n",
        "  plt.plot(history.history[string])\n",
        "  plt.plot(history.history['val_'+string])\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(string)\n",
        "  plt.legend([string, 'val_'+string])\n",
        "  plt.show()\n",
        "  \n",
        "plot_graphs(history, \"accuracy\")\n",
        "plot_graphs(history, \"loss\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}